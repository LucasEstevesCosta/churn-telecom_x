# PROJETO: AnÃ¡lise e PrevisÃ£o de Churn - Telecom X

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?logo=python)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Pandas-data_analysis-brightgreen?logo=pandas)](https://pandas.pydata.org/docs/)
[![Seaborn](https://img.shields.io/badge/Seaborn-visualization-blue?logo=seaborn)](https://seaborn.pydata.org/)
[![Scikit Learn](https://img.shields.io/badge/Scikit--Learn-machine_learning-yellow?logo=scikit-learn)](https://scikit-learn.org/stable/)
[![NumPy](https://img.shields.io/badge/NumPy-numerical-blueviolet?logo=numpy)](https://numpy.org/doc/)

# ğŸ¯ **Objetivo**
Este projeto tem como propÃ³sito prever a **evasÃ£o de clientes (churn)** em uma empresa de telecomunicaÃ§Ãµes fictÃ­cia â€” a **Telecom X** â€” utilizando tÃ©cnicas de **Machine Learning** e **anÃ¡lise exploratÃ³ria de dados**. Este projeto foi criado para o challenge 3 do programa da **Oracle One**, formaÃ§Ã£o de Data Science, do qual faÃ§o parte.

Este projeto tem o objetivo de desenvolver e prÃ¡ticas os conhecimentos adquiridos na formaÃ§Ã£o a fim de tornÃ¡-lo em habilidades prÃ¡ticas.

---

## ğŸš€ VisÃ£o Geral

Este projeto, desenvolvido por **Lucas Esteves Costa** (GitHub: [@LucasEstevesCosta](https://github.com/LucasEstevesCosta)), tem como objetivo a anÃ¡lise exploratÃ³ria e preditiva do *churn* (evasÃ£o de clientes) da empresa fictÃ­cia **Telecom X**. 

O projeto realiza um estudo completo que envolve desde o carregamento e limpeza dos dados atÃ© a criaÃ§Ã£o de modelos de machine learning para previsÃ£o de churn.

---

## ğŸ“‘ ConteÃºdo do Projeto: 
### ğŸ“‹ SumÃ¡rio

1. [ğŸ“¦ ExtraÃ§Ã£o dos Dados](#extraÃ§Ã£o-dos-dados)
   - [â¬‡ï¸ Carregamento do Dataset](#carregamento-do-dataset)
   - [ğŸ” ExploraÃ§Ã£o Inicial](#exploraÃ§Ã£o-inicial)
2. [ğŸ§¹ PreparaÃ§Ã£o dos Dados](#preparaÃ§Ã£o-dos-dados)
   - [ğŸ—‘ï¸ RemoÃ§Ã£o de Colunas](#remoÃ§Ã£o-de-colunas)
   - [ğŸ“ Ajuste de Categorias](#ajuste-de-categorias)
   - [ğŸš« Tratamento de Valores Ausentes](#tratamento-de-valores-ausentes)
   - [ğŸ”¢ Encoding de VariÃ¡veis](#encoding-de-variÃ¡veis)
3. [ğŸ§® AnÃ¡lise de Multicolinearidade](#anÃ¡lise-de-multicolinearidade)
   - [ğŸ”— Agrupamento de Categorias Colineares](#agrupamento-de-categorias-colineares)
   - [ğŸ“Š CÃ¡lculo do VIF](#cÃ¡lculo-do-vif)
   - [âŒ RemoÃ§Ã£o de VariÃ¡veis Redundantes](#remoÃ§Ã£o-de-variÃ¡veis-redundantes)
4. [ğŸ¤– ConstruÃ§Ã£o e Teste dos Modelos](#construÃ§Ã£o-e-teste-dos-modelos)
   - [ğŸ”€ SeparaÃ§Ã£o Treino/Teste](#separaÃ§Ã£o-treino-teste)
   - [ğŸ—ï¸ CriaÃ§Ã£o dos Modelos](#criaÃ§Ã£o-dos-modelos)
   - [âš–ï¸ Balanceamento dos Dados](#balanceamento-dos-dados)
   - [ğŸ“ˆ AvaliaÃ§Ã£o dos Modelos](#avaliaÃ§Ã£o-dos-modelos)
5. [ğŸ’¾ ExportaÃ§Ã£o dos Modelos](#exportaÃ§Ã£o-dos-modelos)
   - [ğŸ“¤ Salvando o Modelo](#salvando-o-modelo)
   - [ğŸ“¥ Carregando e Usando o Modelo](#carregando-e-usando-o-modelo)
6. [ğŸ“Š RelatÃ³rio Final](#relatÃ³rio-final)

---

## ğŸ“¦ ExtraÃ§Ã£o dos Dados

### â¬‡ï¸ Carregamento do Dataset
- O conjunto de dados Ã© carregado diretamente do GitHub para facilitar o uso.

### ğŸ” ExploraÃ§Ã£o Inicial
- SÃ£o verificadas as colunas, tipos de dados e valores ausentes.

## ğŸ§¹ PreparaÃ§Ã£o dos Dados

### ğŸ—‘ï¸ RemoÃ§Ã£o de Colunas
- RemoÃ§Ã£o de colunas sem valor preditivo (ex: `id_cliente`).

### ğŸ“ Ajuste de Categorias
- Ajuste de categorias para facilitar a anÃ¡lise.

### ğŸš« Tratamento de Valores Ausentes
- Tratamento de valores ausentes para garantir qualidade dos dados.

### ğŸ”¢ Encoding de VariÃ¡veis
- TransformaÃ§Ã£o de variÃ¡veis categÃ³ricas em numÃ©ricas (OneHotEncoder).

## ğŸ§® AnÃ¡lise de Multicolinearidade

### ğŸ”— Agrupamento de Categorias Colineares
- Agrupamento de categorias colineares para evitar redundÃ¢ncia.

### ğŸ“Š CÃ¡lculo do VIF
- AnÃ¡lise de VIF para identificar variÃ¡veis com alta multicolinearidade.

### âŒ RemoÃ§Ã£o de VariÃ¡veis Redundantes
- RemoÃ§Ã£o das variÃ¡veis identificadas como redundantes pelo VIF.

## ğŸ¤– ConstruÃ§Ã£o e Teste dos Modelos

### ğŸ”€ SeparaÃ§Ã£o Treino/Teste
- SeparaÃ§Ã£o dos dados em conjuntos de treino e teste.

### ğŸ—ï¸ CriaÃ§Ã£o dos Modelos
- CriaÃ§Ã£o de diferentes modelos preditivos (Random Forest, XGBoost).

### âš–ï¸ Balanceamento dos Dados
- AplicaÃ§Ã£o de tÃ©cnicas de balanceamento para melhorar o desempenho dos modelos.

### ğŸ“ˆ AvaliaÃ§Ã£o dos Modelos
- AvaliaÃ§Ã£o dos modelos por mÃ©tricas como ROC AUC e F1 Score.

## ğŸ’¾ ExportaÃ§Ã£o dos Modelos

### ğŸ“¤ Salvando o Modelo
- ApÃ³s treinar os modelos, eles podem ser exportados para uso futuro em arquivos `.pkl` usando o mÃ³dulo `pickle`.

ApÃ³s treinar os modelos, eles podem ser exportados para uso futuro.  
**Como exportar e usar os modelos:**

- Os modelos sÃ£o salvos em arquivos `.pkl` usando o mÃ³dulo `pickle`.
- Para usar um modelo exportado:
  1. Instale Python e as bibliotecas necessÃ¡rias (`scikit-learn`, `xgboost`).
  2. Carregue o modelo com o comando:
     ```python
     import pickle
     with open('nome_do_arquivo_modelo.pkl', 'rb') as f:
         modelo = pickle.load(f)
     # Para fazer previsÃµes:
     resultado = modelo.predict(novos_dados)
     ```
  3. Substitua `novos_dados` pelos dados que deseja analisar.
- NÃ£o Ã© necessÃ¡rio conhecimento avanÃ§ado: basta seguir o exemplo acima.

## ğŸ“Š RelatÃ³rio Final

- Apresenta as principais conclusÃµes do projeto, como fatores que influenciam a evasÃ£o de clientes.
- InterpretaÃ§Ãµes dos resultados dos modelos.
